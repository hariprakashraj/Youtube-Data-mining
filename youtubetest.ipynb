{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api connection\n",
    "\n",
    "def Api_connect():\n",
    "    api_id=\"AIzaSyBpji4jiGLRlZ8IneRho3zHnExpyPswmRI\"\n",
    "    api_service_name=\"youtube\"\n",
    "    api_version=\"v3\"\n",
    "    youtube=build(api_service_name,api_version,developerKey=api_id)\n",
    "    return youtube\n",
    "youtube=Api_connect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channelinfo\n",
    "\n",
    "def getchannel_info(channel_id):\n",
    "    request=youtube.channels().list(\n",
    "                    part=\"snippet,ContentDetails,statistics\",\n",
    "                    id=channel_id\n",
    "    )\n",
    "    response=request.execute()\n",
    "\n",
    "    for i in response['items']:\n",
    "        data=dict(channel_Name=i['snippet']['title'],\n",
    "                channel_id=i['id'],\n",
    "                channel_Subscribers=i['statistics']['subscriberCount'],\n",
    "                views=i['statistics']['viewCount'],\n",
    "                total_videos=i['statistics']['videoCount'],\n",
    "                channel_description=i['snippet']['description'],\n",
    "                playlist_id=i['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1morep=UCNmfEa6DKdYJMO31VG7UR_g\n",
    "#tharunkumar=UCjvd2JmIWGsEWPmLifUS4PA\n",
    "#mrgk=UC5cY198GU1MQMIPJgMkCJ_Q\n",
    "#sciencewithsam=UChGd9JY4yMegY6PxqpBjpRA\n",
    "#filmicraft=UCYwZ32wCr7grmXst_-3pBZA\n",
    "#mr kk=UCEcKUTiD--VYNW9cNXhQPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video id\n",
    "def get_videos_ids(channel_id):\n",
    "    video_ids=[]\n",
    "\n",
    "    response=youtube.channels().list(id=channel_id,\n",
    "                                        part='contentDetails').execute()\n",
    "    Playlist_id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']      \n",
    "\n",
    "    next_page_token=None\n",
    "\n",
    "    while True:\n",
    "        response1=youtube.playlistItems().list(\n",
    "                                            part='snippet',\n",
    "                                            playlistId=Playlist_id,\n",
    "                                            maxResults=50,\n",
    "                                            pageToken=next_page_token).execute()\n",
    "        for i in range(len(response1['items'])):\n",
    "            video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])  \n",
    "        next_page_token=response1.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videoinformation\n",
    "\n",
    "def get_video_info(video_ids):\n",
    "    video_data=[]\n",
    "\n",
    "    for Video_ids in video_ids:\n",
    "        request=youtube.videos().list(\n",
    "                                    part=\"snippet,contentDetails,statistics\",\n",
    "                                    id=Video_ids\n",
    "        )\n",
    "        response=request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data=dict(channel_name=item['snippet']['channelTitle'],\n",
    "                    channel_id=item['snippet']['channelId'],\n",
    "                    Video_id=item['id'],\n",
    "                    title=item['snippet']['title'],\n",
    "                    tags=item['snippet'].get('tags'),\n",
    "                    thumbnail=item['snippet']['thumbnails']['default']['url'],\n",
    "                    description=item['snippet'].get('description'),\n",
    "                    date_published=item['snippet']['publishedAt'],\n",
    "                    duration=item['contentDetails']['duration'],\n",
    "                    views=item['statistics'].get('viewCount'),\n",
    "                    likes=item['statistics'].get('likeCount'),\n",
    "                    comments=item['statistics'].get('commentCount'),\n",
    "                    favourite_count=item['statistics']['favoriteCount'],\n",
    "                    Definition=item['contentDetails']['definition'],\n",
    "                    caption_status=item['contentDetails']['caption'])\n",
    "            video_data.append(data)\n",
    "    return video_data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get comment details\n",
    "\n",
    "def get_comment_info(video_ids):\n",
    "    comment_data=[]\n",
    "\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            request=youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                maxResults=50\n",
    "            )\n",
    "            response=request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                data=dict(Comment_Id=item['snippet']['topLevelComment']['id'],\n",
    "                        Video_id=item['snippet']['topLevelComment']['snippet']['videoId'],\n",
    "                        Comment_text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                        Comment_author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                        Commented_date=item['snippet']['topLevelComment']['snippet']['publishedAt'])\n",
    "                \n",
    "            comment_data.append(data)\n",
    "\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return comment_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_playlist_details\n",
    "\n",
    "def get_playlist_info(channel_id):\n",
    "\n",
    "    next_page_token=None\n",
    "\n",
    "    All_data=[]\n",
    "\n",
    "    while True:\n",
    "        request=youtube.playlists().list(\n",
    "            part='snippet,contentDetails',\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response=request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data=dict(Playlist_id=item['id'],\n",
    "                    Title=item['snippet']['title'],\n",
    "                    channel_id=item['snippet']['channelId'],\n",
    "                    channel_name=item['snippet']['channelTitle'],\n",
    "                    Published_at=item['snippet']['publishedAt'],\n",
    "                    video_count=item['contentDetails']['itemCount'])\n",
    "            All_data.append(data)\n",
    "    \n",
    "        \n",
    "        next_page_token=response.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return All_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting mongo db \n",
    "\n",
    "client=pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db=client['Youtube_Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_details(channel_id):\n",
    "    ch_detail=getchannel_info(channel_id)\n",
    "    vi_ids=get_videos_ids(channel_id)\n",
    "    vi_detail=get_video_info(vi_ids)\n",
    "    comm_detail=get_comment_info(vi_ids)\n",
    "    pl_detail=get_playlist_info(channel_id)\n",
    "\n",
    "    coll1=db[\"channel_details\"]\n",
    "    coll1.insert_one({\"channel_information\":ch_detail,\"playlist_information\":pl_detail,\n",
    "                      \"video_details\":vi_detail,\"comment_details\":comm_detail})\n",
    "    \n",
    "    return \"Uploaded to MongoDB Successfully.\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrgk=UC5cY198GU1MQMIPJgMkCJ_Q\n",
    "#filmicraft=UCYwZ32wCr7grmXst_-3pBZA\n",
    "#alphatamizhan=UCr1SKz3fXmqlBU7SZSlMA4Q\n",
    "#mr kk=UCEcKUTiD--VYNW9cNXhQPSA\n",
    "#jk=UC_HZY9d5wJ-MEiuq6vhx8hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating channel tables in sql\n",
    "\n",
    "def channels_table():\n",
    "\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"Hariprakash@04\",\n",
    "                        database=\"_youtube_data_\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query='''drop table if exists channels'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query='''create table if not exists channels(channel_Name varchar(100),\n",
    "                                                            channel_id varchar(100) primary key,\n",
    "                                                            channel_Subscribers bigint,\n",
    "                                                            views bigint,\n",
    "                                                            total_videos bigint,\n",
    "                                                            channel_description text,\n",
    "                                                            playlist_id varchar(1000))'''\n",
    "        \n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        \n",
    "    except:\n",
    "        print(\"channels table already created!\")    \n",
    "\n",
    "\n",
    "\n",
    "    ch_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for ch_data in coll.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df=pd.DataFrame(ch_list)   \n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query='''insert into channels(channel_Name,\n",
    "                                            channel_id,\n",
    "                                            channel_Subscribers,\n",
    "                                            views,\n",
    "                                            total_videos,\n",
    "                                            channel_description,\n",
    "                                            playlist_id)\n",
    "                                            \n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "        values=(row['channel_Name'],\n",
    "                row['channel_id'],\n",
    "                row['channel_Subscribers'],\n",
    "                row['views'],\n",
    "                row['total_videos'],\n",
    "                row['channel_description'],\n",
    "                row['playlist_id'])\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "\n",
    "        except:\n",
    "            print(\"channel values are already inserted!\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating playlists table in sql\n",
    "\n",
    "def playlist_table():\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"Hariprakash@04\",\n",
    "                        database=\"_youtube_data_\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query='''drop table if exists playlists'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "\n",
    "    create_query='''create table if not exists playlists(Playlist_id varchar(100) primary key,\n",
    "                                                        Title varchar(100),\n",
    "                                                        channel_id varchar(100),\n",
    "                                                        channel_name varchar(100),\n",
    "                                                        Published_at timestamp,\n",
    "                                                        video_count int)'''\n",
    "\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for pl_data in coll.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "\n",
    "    df1=pd.DataFrame(pl_list)\n",
    "\n",
    "\n",
    "    for index,row in df1.iterrows():\n",
    "            insert_query='''insert into playlists(Playlist_id,\n",
    "                                                Title,\n",
    "                                                channel_id,\n",
    "                                                channel_name,\n",
    "                                                Published_at,\n",
    "                                                video_count)\n",
    "                                                \n",
    "                                                values(%s,%s,%s,%s,%s,%s)'''\n",
    "            values=(row['Playlist_id'],\n",
    "                    row['Title'],\n",
    "                    row['channel_id'],\n",
    "                    row['channel_name'],\n",
    "                    row['Published_at'],\n",
    "                    row['video_count'])\n",
    "\n",
    "\n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating videos table in sql\n",
    "\n",
    "def videos_table():\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"Hariprakash@04\",\n",
    "                        database=\"_youtube_data_\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query='''drop table if exists videos'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "\n",
    "    create_query='''create table if not exists videos(channel_name varchar(100),\n",
    "                                                        channel_id varchar(100) ,\n",
    "                                                        Video_id varchar(20) primary key,\n",
    "                                                        title varchar(200),\n",
    "                                                        tags text,\n",
    "                                                        thumbnail varchar(200),\n",
    "                                                        description text,\n",
    "                                                        date_published timestamp,\n",
    "                                                        duration interval,\n",
    "                                                        views bigint,\n",
    "                                                        likes bigint,\n",
    "                                                        comments int,\n",
    "                                                        favourite_count int,\n",
    "                                                        Definition varchar(20),\n",
    "                                                        caption_status varchar(20))'''\n",
    "\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    vi_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for vi_data in coll.find({},{\"_id\":0,\"video_details\":1}):\n",
    "        for i in range(len(vi_data[\"video_details\"])):\n",
    "            vi_list.append(vi_data[\"video_details\"][i])\n",
    "    df2=pd.DataFrame(vi_list)\n",
    "\n",
    "    for index,row in df2.iterrows():\n",
    "                insert_query='''insert into videos(channel_name,\n",
    "                                                    channel_id,\n",
    "                                                    Video_id,\n",
    "                                                    title,\n",
    "                                                    tags,\n",
    "                                                    thumbnail,\n",
    "                                                    description,\n",
    "                                                    date_published,\n",
    "                                                    duration,\n",
    "                                                    views,\n",
    "                                                    likes,\n",
    "                                                    comments,\n",
    "                                                    favourite_count,\n",
    "                                                    Definition,\n",
    "                                                    caption_status)\n",
    "                                                \n",
    "                                                    values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "                values=(row['channel_name'],\n",
    "                        row['channel_id'],\n",
    "                        row['Video_id'],\n",
    "                        row['title'],\n",
    "                        row['tags'],\n",
    "                        row['thumbnail'],\n",
    "                        row['description'],\n",
    "                        row['date_published'],\n",
    "                        row['duration'],\n",
    "                        row['views'],\n",
    "                        row['likes'],\n",
    "                        row['comments'],\n",
    "                        row['favourite_count'],\n",
    "                        row['Definition'],\n",
    "                        row['caption_status'])\n",
    "                        \n",
    "\n",
    "\n",
    "                cursor.execute(insert_query,values)\n",
    "                mydb.commit()    \n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating comments table in sql\n",
    "\n",
    "def comment_tables():\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"Hariprakash@04\",\n",
    "                        database=\"_youtube_data_\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    drop_query='''drop table if exists comments'''\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "\n",
    "    create_query='''create table if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                                                        Video_id varchar(100),\n",
    "                                                        Comment_text text,\n",
    "                                                        Comment_author varchar(100),\n",
    "                                                        Commented_date timestamp)'''\n",
    "\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "\n",
    "\n",
    "    cmt_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for cmt_data in coll.find({},{\"_id\":0,\"comment_details\":1}):\n",
    "        for i in range(len(cmt_data[\"comment_details\"])):\n",
    "            cmt_list.append(cmt_data[\"comment_details\"][i])\n",
    "    df3=pd.DataFrame(cmt_list)\n",
    "\n",
    "\n",
    "    mydb=psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"Hariprakash@04\",\n",
    "                        database=\"_youtube_data_\",\n",
    "                        port=\"5432\")\n",
    "    cursor=mydb.cursor()\n",
    "\n",
    "    for index,row in df3.iterrows():\n",
    "                insert_query='''insert into comments(Comment_Id,\n",
    "                                                        Video_id,\n",
    "                                                        Comment_text,\n",
    "                                                        Comment_author,\n",
    "                                                        Commented_date\n",
    "                                                        )\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s)'''\n",
    "                \n",
    "\n",
    "\n",
    "                values=(row['Comment_Id'],\n",
    "                        row['Video_id'],\n",
    "                        row['Comment_text'],\n",
    "                        row['Comment_author'],\n",
    "                        row['Commented_date']\n",
    "                        )\n",
    "\n",
    "\n",
    "                cursor.execute(insert_query,values)\n",
    "                mydb.commit()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_table()\n",
    "    playlist_table()\n",
    "    videos_table()\n",
    "    comment_tables()\n",
    "\n",
    "    return \"Tables created successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel_table():\n",
    "    ch_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for ch_data in coll.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df=st.dataframe(ch_list)   \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlist_table():\n",
    "    pl_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for pl_data in coll.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df1=st.dataframe(pl_list)\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "    vi_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for vi_data in coll.find({},{\"_id\":0,\"video_details\":1}):\n",
    "        for i in range(len(vi_data[\"video_details\"])):\n",
    "            vi_list.append(vi_data[\"video_details\"][i])\n",
    "    df2=st.dataframe(vi_list)\n",
    "\n",
    "    return  df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "    cmt_list=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for cmt_data in coll.find({},{\"_id\":0,\"comment_details\":1}):\n",
    "        for i in range(len(cmt_data[\"comment_details\"])):\n",
    "            cmt_list.append(cmt_data[\"comment_details\"][i])\n",
    "    df3=st.dataframe(cmt_list)\n",
    "\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit code\n",
    "\n",
    "st.set_page_config(page_title= \"Youtube Data Harvesting and Warehousing |\",\n",
    "                   layout= \"wide\",\n",
    "                   initial_sidebar_state= \"expanded\",)\n",
    "st.title(\":red[Youtube Data Harvesting and Warehousing]\")\n",
    "with st.sidebar:\n",
    "    st.image(\"https://t3.ftcdn.net/jpg/05/07/46/84/360_F_507468479_HfrpT7CIoYTBZSGRQi7RcWgo98wo3vb7.jpg\")\n",
    "    st.header(\":green[Overview]\")\n",
    "    st.subheader(\"YouTube Data Harvesting and Warehousing is a project that aims to allow users to access and analyze data from multiple YouTube channels. The project utilizes SQL, MongoDB, and Streamlit to create a user-friendly application that allows users to retrieve, store, and query YouTube channel and video data.\")\n",
    "    st.header(\":green[Tools used in this project:]\")\n",
    "    st.subheader(\"1.API Integration \")\n",
    "    st.subheader(\"2.MongoDB (Document Database)\")\n",
    "    st.subheader(\"3.SQL (Structured Database)\")\n",
    "    st.subheader(\"4.Streamlit (To visualize)\")\n",
    "\n",
    "    st.header(\":green[Steps Approached:]\")\n",
    "    st.subheader(\"Step 1:\")\n",
    "    st.caption(\"Connecting to the YouTube API by making requests to API to get data\")\n",
    "    st.subheader(\"Step 2:\")\n",
    "    st.caption(\"Storing the data in a MongoDB data lake since it will be a document.\")\n",
    "    st.subheader(\"Step 3:\")\n",
    "    st.caption(\"Migrating the Data to the SQL Warehouse to get a structured data format.\")\n",
    "    st.subheader(\"Step 4:\")\n",
    "    st.caption(\"Using SQL queries to join the tables in the SQL data warehouse and retrieve data for specific channels based on user input.\")\n",
    "    st.subheader(\"Step 5:\")\n",
    "    st.caption(\"Displaying the retrieved data in the Streamlit app.\")\n",
    "channel_id=st.text_input(\"Enter the Channel ID:\")    \n",
    "\n",
    "if st.button(\"Collect and Store Data in :blue[MondoDB]:\"):\n",
    "    ch_ids=[]\n",
    "    db=client[\"Youtube_Data\"]\n",
    "    coll=db[\"channel_details\"]\n",
    "    for ch_data in coll.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_ids.append(ch_data[\"channel_information\"][\"channel_id\"])\n",
    "\n",
    "    if channel_id in ch_ids:\n",
    "        st.success(\"Channel Details already exists!\")\n",
    "\n",
    "    else:\n",
    "        insert=channel_details(channel_id)  \n",
    "        st.success(insert)      \n",
    "\n",
    "    if st.button(\"Migrate to :blue[SQL]\"):\n",
    "        Tables=tables() \n",
    "        st.success(Tables)   \n",
    "\n",
    "    show_table=st.radio(\"Select to view Tables\",(\"CHANNELS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
    "\n",
    "    if show_table==\"CHANNELS\":\n",
    "        show_channel_table()\n",
    "\n",
    "    if show_table==\"PLAYLISTS\":\n",
    "        show_playlist_table()\n",
    "\n",
    "    if show_table==\"VIDEOS\":\n",
    "        show_videos_table()\n",
    "\n",
    "    if show_table==\"COMMENTS\":\n",
    "        show_comments_table() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql connection\n",
    "\n",
    "mydb=psycopg2.connect(host=\"localhost\",\n",
    "                    user=\"postgres\",\n",
    "                    password=\"Hariprakash@04\",\n",
    "                    database=\"_youtube_data_\",\n",
    "                    port=\"5432\")\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "question=st.selectbox(\"Select your Question\",(\"1.What are the names of all the videos and their corresponding channels?\",\n",
    "                                              \"2.Which channels have the most number of videos, and how many videos do they have?\",\n",
    "                                              \"3.What are the top 10 most viewed videos and their respective channels?\",\n",
    "                                              \"4.How many comments were made on each video, and what are their corresponding video names?\",\n",
    "                                              \"5.Which videos have the highest number of likes, and what are their corresponding channel names?\",\n",
    "                                              \"6.What is the total number of likes and dislikes for each video, and what are their corresponding video names?\",\n",
    "                                              \"7.What is the total number of views for each channel, and what are their corresponding channel names?\",\n",
    "                                              \"8.What are the names of all the channels that have published videos in the year 2022?\",\n",
    "                                              \"9.What is the average duration of all videos in each channel, and what are their corresponding channel names?\",\n",
    "                                              \"10.Which videos have the highest number of comments, and what are their corresponding channel names?\"))\n",
    "\n",
    "if question==\"1.What are the names of all the videos and their corresponding channels?\":\n",
    "    query1='''select title as videos,channel_name as channelname from videos'''     \n",
    "    cursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=cursor.fetchall()\n",
    "\n",
    "    df=pd.DataFrame(t1,columns=[\"Video Title\",\"Channel Name\"])\n",
    "    df\n",
    "    st.write(df)\n",
    "\n",
    "elif question==\"2.Which channels have the most number of videos, and how many videos do they have?\":\n",
    "    query2='''select channel_name as channelname,total_videos as no_of_videos from channels\n",
    "                order by total_videos desc'''     \n",
    "    cursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t2=cursor.fetchall()\n",
    "\n",
    "    df2=pd.DataFrame(t2,columns=[\"Channle Name\",\"No.of Videos\"])\n",
    "    df2\n",
    "    st.write(df2)    \n",
    "\n",
    "elif question==\"3.What are the top 10 most viewed videos and their respective channels?\":\n",
    "    query3='''select views as views,channel_name as channelname,title as videotitle from videos\n",
    "            where views is not null order by views desc limit 10'''     \n",
    "    cursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t3=cursor.fetchall()\n",
    "\n",
    "    df3=pd.DataFrame(t3,columns=[\"Views\",\"Channel Name\",\"Title\"])\n",
    "    df3\n",
    "    st.write(df3)\n",
    "\n",
    "elif question==\"4.How many comments were made on each video, and what are their corresponding video names?\":\n",
    "    query4='''select comments as no_comments,title as videotitle from videos \n",
    "            where comments is not null'''     \n",
    "    cursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t4=cursor.fetchall()\n",
    "\n",
    "    df4=pd.DataFrame(t4,columns=[\"Number of Comments\",\"Video Title\"])\n",
    "    df4    \n",
    "    st.write(df4)\n",
    "\n",
    "elif question==\"5.Which videos have the highest number of likes, and what are their corresponding channel names?\":\n",
    "    query5='''select title as videotitle,channel_name as channelname,likes as likecount from videos \n",
    "            where likes is not null order by likes desc'''     \n",
    "    cursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t5=cursor.fetchall()\n",
    "\n",
    "    df5=pd.DataFrame(t5,columns=[\"Video Title\",\"Channel Name\",\"Like Count\"])\n",
    "    df5    \n",
    "    st.write(df5)\n",
    "\n",
    "elif question==\"6.What is the total number of likes, and what are their corresponding video names?\":\n",
    "    query6='''select likes as likecount,title as videotitle from videos'''     \n",
    "    cursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t6=cursor.fetchall()\n",
    "\n",
    "    df6=pd.DataFrame(t6,columns=[\"Like Count\",\"Video Title\"])\n",
    "    df6    \n",
    "    st.write(df6)\n",
    "\n",
    "elif question==\"7.What is the total number of views for each channel, and what are their corresponding channel names?\":\n",
    "    query7='''select views as totalviews,channel_name as channelname from channels'''     \n",
    "    cursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t7=cursor.fetchall()\n",
    "\n",
    "    df7=pd.DataFrame(t7,columns=[\"Total Views\",\"Channel Name\"])\n",
    "    df7\n",
    "    st.write(df7)\n",
    "\n",
    "    \n",
    "elif question==\"8.What are the names of all the channels that have published videos in the year 2022?\":\n",
    "    query8='''select title as videotitle,date_published as publishedat,channel_name as channelname from videos\n",
    "            where extract(year from date_published)=2022'''     \n",
    "    cursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t8=cursor.fetchall()\n",
    "\n",
    "    df8=pd.DataFrame(t8,columns=[\"Video Title\",\"Published at\",\"Channel Name\"])\n",
    "    df8\n",
    "    st.write(df8)\n",
    "\n",
    "elif question==\"9.What is the average duration of all videos in each channel, and what are their corresponding channel names?\":\n",
    "    query9='''select channel_name as channelname,AVG(duration) as averageduration from videos\n",
    "            group by channel_name'''     \n",
    "    cursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t9=cursor.fetchall()\n",
    "\n",
    "    df9=pd.DataFrame(t9,columns=[\"Channel Name\",\"Average Duration\"])\n",
    "    df9\n",
    "\n",
    "    T9=[]\n",
    "    for index,row in df9.iterrows():\n",
    "        channel_title=row[\"Channel Name\"]\n",
    "        average_duration=row[\"Average Duration\"]\n",
    "        average_duration_str=str(average_duration)\n",
    "        T9.append(dict(channeltitle=channel_title,avgduration=average_duration_str))\n",
    "    df1=pd.DataFrame(T9)      \n",
    "    st.write(df1)\n",
    "\n",
    "elif question==10.Which videos have the highest number of comments, and what are their corresponding channel names?\":\n",
    "    query10='''select title as title,channel_name as channelname,comments as comments from videos\n",
    "            where comments is not null order by comments desc'''     \n",
    "    cursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=cursor.fetchall()\n",
    "\n",
    "    df10=pd.DataFrame(t10,columns=[\"Video Title\",\"Channel Name\",\"No.of Comments\"])\n",
    "    df10    \n",
    "    st.write(df10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Title</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>No.of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weapons of Mass destruction and Iraq üáÆüá∂</td>\n",
       "      <td>Hacked History</td>\n",
       "      <td>140444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The US invasion of Iraq</td>\n",
       "      <td>Hacked History</td>\n",
       "      <td>27361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dreams that came TRUE! üßõ‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>JK</td>\n",
       "      <td>17052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Leaders of countries</td>\n",
       "      <td>Hacked History</td>\n",
       "      <td>16322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Greatest Strategists in history</td>\n",
       "      <td>Hacked History</td>\n",
       "      <td>13353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>How to Handle you Emotions &amp; Pain | Tamil | Al...</td>\n",
       "      <td>Alpha Tamizhan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Unknown Story behind Interstellar - in Tamil |...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>üî•Amazing ISRO Rocket Toys On AmazonüòÆ | Science...</td>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>How to IRON a shirt|Easy and perfect at home |...</td>\n",
       "      <td>Alpha Tamizhan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Alpha tamizhan Live Stream</td>\n",
       "      <td>Alpha Tamizhan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Video Title     Channel Name  \\\n",
       "0               Weapons of Mass destruction and Iraq üáÆüá∂  Hacked History    \n",
       "1                               The US invasion of Iraq  Hacked History    \n",
       "2                           Dreams that came TRUE! üßõ‚Äç‚ôÇÔ∏è              JK    \n",
       "3                             Best Leaders of countries  Hacked History    \n",
       "4                    12 Greatest Strategists in history  Hacked History    \n",
       "...                                                 ...              ...   \n",
       "1171  How to Handle you Emotions & Pain | Tamil | Al...   Alpha Tamizhan   \n",
       "1172  Unknown Story behind Interstellar - in Tamil |...           Mr. GK   \n",
       "1173  üî•Amazing ISRO Rocket Toys On AmazonüòÆ | Science...           Mr. GK   \n",
       "1174  How to IRON a shirt|Easy and perfect at home |...   Alpha Tamizhan   \n",
       "1175                         Alpha tamizhan Live Stream   Alpha Tamizhan   \n",
       "\n",
       "      No.of Comments  \n",
       "0             140444  \n",
       "1              27361  \n",
       "2              17052  \n",
       "3              16322  \n",
       "4              13353  \n",
       "...              ...  \n",
       "1171               2  \n",
       "1172               0  \n",
       "1173               0  \n",
       "1174               0  \n",
       "1175               0  \n",
       "\n",
       "[1176 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydb=psycopg2.connect(host=\"localhost\",\n",
    "                    user=\"postgres\",\n",
    "                    password=\"Hariprakash@04\",\n",
    "                    database=\"_youtube_data_\",\n",
    "                    port=\"5432\")\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "\n",
    "#elif question==10.Which videos have the highest number of comments, and what are their corresponding channel names?\":\n",
    "query10='''select title as title,channel_name as channelname,comments as comments from videos\n",
    "           where comments is not null order by comments desc'''     \n",
    "cursor.execute(query10)\n",
    "mydb.commit()\n",
    "t10=cursor.fetchall()\n",
    "\n",
    "df10=pd.DataFrame(t10,columns=[\"Video Title\",\"Channel Name\",\"No.of Comments\"])\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channeltitle</th>\n",
       "      <th>avgduration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. GK</td>\n",
       "      <td>0 days 00:09:20.303158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JK</td>\n",
       "      <td>0 days 00:11:24.213873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hacked History</td>\n",
       "      <td>0 days 00:00:24.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filmi Craft Corner</td>\n",
       "      <td>0 days 00:12:43.926702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr. KK - GNS</td>\n",
       "      <td>0 days 00:02:01.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alpha Tamizhan</td>\n",
       "      <td>0 days 00:06:17.078431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         channeltitle             avgduration\n",
       "0              Mr. GK  0 days 00:09:20.303158\n",
       "1                 JK   0 days 00:11:24.213873\n",
       "2     Hacked History   0 days 00:00:24.064935\n",
       "3  Filmi Craft Corner  0 days 00:12:43.926702\n",
       "4        Mr. KK - GNS  0 days 00:02:01.400000\n",
       "5      Alpha Tamizhan  0 days 00:06:17.078431"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
